{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bittflowvirtualenvwrapperff4a3ff39ecc4e298fd2c21fd802ff24",
   "display_name": "Python 3.8.5 64-bit ('tflow': virtualenvwrapper)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Playing with CIFAR-10\n",
    "CIFAR-10 dataset is a bit more advanced data set than mnist. In this dataset images are 32x32 pixels and they are colored RGB with three color channels. Plus the images are not perfectly centered as in mnist. There are 10 labels in the data and there are 50,000 training images. There are 10,000 validation images as well.\n",
    "\n",
    "## Applying convolution\n",
    "We had witnessed first hand that applying convolutions to the model resulted in better performance by mnist data set. So applying filters and pooling, help extract features from the data which then help in classification. We expect a CNN should give us great results with CIFAR-10 as well. \n",
    "\n",
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 85s 54ms/step - loss: 1.8778 - accuracy: 0.2973 - val_loss: 1.3360 - val_accuracy: 0.5142\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 80s 51ms/step - loss: 1.3032 - accuracy: 0.5318 - val_loss: 1.2728 - val_accuracy: 0.5489\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 86s 55ms/step - loss: 1.1320 - accuracy: 0.6003 - val_loss: 1.0770 - val_accuracy: 0.6178\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 76s 49ms/step - loss: 1.0348 - accuracy: 0.6360 - val_loss: 1.0303 - val_accuracy: 0.6417\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 0.9549 - accuracy: 0.6659 - val_loss: 0.9534 - val_accuracy: 0.6653\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc1d4335040>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load and normalize data\n",
    "cifar = tf.keras.datasets.cifar10\n",
    "(trainImgs, trainLbls), (valImgs, valLbls) = cifar.load_data()\n",
    "trainImgs = trainImgs/255.0\n",
    "valImgs = valImgs/255.0\n",
    "\n",
    "# define model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu, input_shape=(32,32,3)),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics='accuracy'\n",
    ")\n",
    "\n",
    "model.fit(trainImgs, trainLbls, validation_data=(valImgs, valLbls), epochs=20)"
   ]
  },
  {
   "source": [
    "I ran this code in colab so that I could run it in GPU. for 20 epochs, I could get about 70% validation accuracy and training accuracy of about 80%. Not too great. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}